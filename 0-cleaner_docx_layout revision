from typing import Union
import io
import zipfile
from lxml import etree
from docx import Document

# Optional import for frameworks like FastAPI
try:
    from fastapi import UploadFile
except ImportError:
    UploadFile = None

# WordprocessingML XML namespace
NAMESPACES = {
    'w': 'http://schemas.openxmlformats.org/wordprocessingml/2006/main'
}

def clean_docx_from_bytes(file_data: Union['UploadFile', bytes], diagnostics: bool = False) -> Document:
    """
    Cleans a .docx file by:
    - Accepting all insertions
    - Replacing deletions with empty runs to preserve structure
    - Removing comments and tracked changes
    - Removing rsid* metadata
    Returns a clean python-docx Document object.

    Args:
        file_data (UploadFile or bytes): The DOCX content
        diagnostics (bool): Show cleanup summary per XML part (optional)

    Returns:
        Document: A cleaned and ready-to-use python-docx object
    """

    def get_bytes(data):
        if hasattr(data, "file"):
            return data.file.read()
        elif isinstance(data, bytes):
            return data
        raise TypeError("file_data must be UploadFile or bytes")

    def clean_xml(xml_data: bytes, filename: str) -> bytes:
        xml = etree.fromstring(xml_data)

        if diagnostics:
            def count(tag): return len(xml.xpath(f'//w:{tag}', namespaces=NAMESPACES))
            print(f"üìÑ {filename}")
            print(f"  üó®Ô∏è Comments:               {count('commentReference')}")
            print(f"  ‚ûï Insertions:             {count('ins')}")
            print(f"  ‚ûñ Deletions:              {count('del')}")
            print(f"  üîÅ Moves:                  {count('moveFrom') + count('moveTo')}")
            print(f"  üé® Formatting revisions:   {count('rPrChange') + count('pPrChange') + count('tblPrChange')}")
            print()

        # Accept insertions: keep content of <w:ins> and discard the wrapper
        for ins in xml.xpath('//w:ins', namespaces=NAMESPACES):
            parent = ins.getparent()
            index = parent.index(ins)
            for child in list(ins):
                parent.insert(index, child)
                index += 1
            parent.remove(ins)

        # Replace deletions with empty runs to preserve layout
        for deletion in xml.xpath('//w:del', namespaces=NAMESPACES):
            parent = deletion.getparent()
            index = parent.index(deletion)

            # üõ†Ô∏è MS Word preserves layout (tables, cells, spacing, line breaks) even when text is deleted.
            # So instead of removing <w:del> entirely, we insert an empty <w:r><w:t></w:t></w:r>
            # This ensures the layout stays visually and structurally intact.
            blank_run = etree.Element(f"{{{NAMESPACES['w']}}}r")
            blank_text = etree.SubElement(blank_run, f"{{{NAMESPACES['w']}}}t")
            blank_text.text = ""

            parent.insert(index, blank_run)
            parent.remove(deletion)

        # Remove all other tracked change and revision tags
        tags_to_remove = [
            'moveFrom', 'moveTo',
            'commentRangeStart', 'commentRangeEnd', 'commentReference',
            'rPrChange', 'pPrChange', 'tblPrChange',
            'proofErr', 'permStart', 'permEnd',
            'bookmarkStart', 'bookmarkEnd', 'trackChanges'
        ]
        for tag in tags_to_remove:
            for elem in xml.xpath(f'//w:{tag}', namespaces=NAMESPACES):
                if elem.getparent() is not None:
                    elem.getparent().remove(elem)

        # Remove rsid* attributes used for revision sessions
        for elem in xml.iter():
            for attr in list(elem.attrib):
                if 'rsid' in attr:
                    del elem.attrib[attr]

        return etree.tostring(xml, encoding='UTF-8', xml_declaration=True, standalone="yes")

    # Load bytes from UploadFile or raw bytes
    raw_bytes = get_bytes(file_data)
    input_buffer = io.BytesIO(raw_bytes)
    output_buffer = io.BytesIO()

    # Read and rewrite the .docx archive, cleaning tracked parts
    with zipfile.ZipFile(input_buffer, 'r') as zin:
        with zipfile.ZipFile(output_buffer, 'w', zipfile.ZIP_DEFLATED) as zout:
            for item in zin.infolist():
                data = zin.read(item.filename)

                if item.filename.startswith("word/") and item.filename.endswith(".xml"):
                    if item.filename == 'word/comments.xml':
                        data = b''  # remove comments.xml entirely
                    else:
                        try:
                            data = clean_xml(data, item.filename)
                        except Exception as e:
                            print(f"[ERROR] Failed to clean {item.filename}: {e}")

                zout.writestr(item, data)

    output_buffer.seek(0)
    return Document(output_buffer)
